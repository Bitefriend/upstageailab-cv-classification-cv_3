{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86372f1b965adb5",
   "metadata": {},
   "source": "# Notebook 기본 세팅"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbee03e090649db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:12.255749Z",
     "start_time": "2025-07-06T10:19:12.251094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constant 선언\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 식별하기 위한 마커 파일 이름\n",
    "ROOT_MARKER = \"pyproject.toml\"\n",
    "\n",
    "# 한글 표시를 위한 나눔바른고딕 폰트 파일 이름\n",
    "# matplotlib 의 font_manager 에 실제 폰트 파일의 위치를 넣어주어야 한다.\n",
    "KOREAN_FONT_FILE = \"NanumBarunGothic.ttf\"\n",
    "\n",
    "# matplotlib 에서는 font-family 의 이름으로 font 를 설정한다.\n",
    "# 그래서 font 파일 그 자체가 아니라, 그 파일의 family 이름을 적어준다.\n",
    "KOREAN_FONT_FAMILY = \"NanumBarunGothic\"\n",
    "\n",
    "# 참고\n",
    "# Font Family 와 Font File 의 차이는,\n",
    "# Font Family 는 비슷한 디자인 특성을 공유하는 글꼴 그룹을 의미한다.\n",
    "#\n",
    "# 예를 들어 '나눔바른고딕' 폰트 패밀리는 일반(Regular), 굵게(Bold), 기울임(Italic) 등 여러 스타일을 포함할 수 있다.\n",
    "# 반면, 폰트 파일(.ttf, .otf 등)은 이러한 폰트의 하나의 스타일이 저장된 실제 파일이다.\n",
    "#\n",
    "# 이 프로젝트에서는 폰트 용량을 줄이기 위해 일반(Regular) 인 NanumBarunGothic.ttf 만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f2746669fe3b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:12.355749Z",
     "start_time": "2025-07-06T10:19:12.353291Z"
    }
   },
   "outputs": [],
   "source": [
    "# 프로젝트 root 를 sys.path 에 추가해서 import 구문을 사용하기 쉽게\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    pyproject.toml 파일을 기준으로 루트 디렉토리를 찾는다.\n",
    "    :return: Path: 프로젝트 루트 디렉토리 경로\n",
    "    \"\"\"\n",
    "\n",
    "    current_path = Path().resolve()\n",
    "\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / ROOT_MARKER).exists():\n",
    "            return current_path\n",
    "\n",
    "        current_path = current_path.parent\n",
    "\n",
    "    raise FileNotFoundError(\"프로젝트 루트 디렉토리를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "ROOT_DIR = find_project_root()\n",
    "DATA_DIR = ROOT_DIR / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2102dd84f4bdc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:12.590961Z",
     "start_time": "2025-07-06T10:19:12.360973Z"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib 의 한글 font 설정\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "FONTS_DATA_DIR = DATA_DIR / \"fonts\"\n",
    "\n",
    "\n",
    "def setup_korean_font():\n",
    "    font_path = FONTS_DATA_DIR / KOREAN_FONT_FILE\n",
    "    fm.fontManager.addfont(font_path)\n",
    "\n",
    "    # 폰트 설정\n",
    "    plt.rcParams[\"font.family\"] = KOREAN_FONT_FAMILY\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "\n",
    "setup_korean_font()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8d04607dc6327",
   "metadata": {},
   "source": "# DocumentImageClassifier 를 사용해보기"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135a7c6f3a7571cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:15.146170Z",
     "start_time": "2025-07-06T10:19:12.595964Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.model.classifier import DocumentImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228256364509d389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:15.153642Z",
     "start_time": "2025-07-06T10:19:15.152063Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 432\n",
    "MODEL_NAME = \"resnet34\"\n",
    "LEARNING_RATE = 1e-3\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "VAL_RATE = 0.2\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1430ae980cd64ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:15.667636Z",
     "start_time": "2025-07-06T10:19:15.158280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentImageClassifier(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (train_accuracy): MulticlassAccuracy()\n",
       "  (train_f1): MulticlassF1Score()\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (val_f1): MulticlassF1Score()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       "  (test_f1): MulticlassF1Score()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DocumentImageClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_classes=17,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b4349d93a73e0",
   "metadata": {},
   "source": [
    "## PyTorch Lightning의 Trainer와 함께 사용해보기\n",
    "\n",
    "### Trainer 매개변수 설명\n",
    "\n",
    "#### 🔴 필수 설정 (반드시 고려해야 함)\n",
    "- **max_epochs** (기본값: `None`)\n",
    "  - 총 학습할 에포크 수를 설정합니다.\n",
    "  - 기본값이 `None`이므로 무한 학습됩니다. 실제로는 필수 설정입니다.\n",
    "\n",
    "#### 🟡 권장 설정 (기본값이 있지만 명시 권장)\n",
    "- **accelerator** (기본값: `\"auto\"`)\n",
    "  - 사용할 하드웨어 가속기를 지정합니다.\n",
    "  - `\"auto\"`: 자동 선택\n",
    "  - `\"cpu\"`: CPU 사용\n",
    "  - `\"gpu\"`: GPU 사용 (CUDA)\n",
    "  - `\"mps\"`: Apple Silicon GPU 사용\n",
    "\n",
    "- **devices** (기본값: `\"auto\"`)\n",
    "  - 사용할 디바이스 수나 특정 디바이스를 지정합니다.\n",
    "  - `\"auto\"`: 사용 가능한 모든 디바이스\n",
    "  - `1`, `2`: 디바이스 개수\n",
    "  - `[0, 1]`: 특정 디바이스 ID\n",
    "\n",
    "- **precision** (기본값: `\"32-true\"`)\n",
    "  - 연산 정밀도를 설정하여 메모리 사용량과 속도를 최적화합니다.\n",
    "  - `\"32\"`: 32비트 부동소수점 (기본값)\n",
    "  - `\"16-mixed\"`: 16비트 혼합 정밀도 (AMP) - 메모리 절약 권장\n",
    "  - `\"bf16-mixed\"`: BFloat16 혼합 정밀도\n",
    "\n",
    "#### 🟢 선택 사항 (기본값으로 충분)\n",
    "- **callbacks** (기본값: `None`)\n",
    "  - 학습 과정에서 실행할 콜백 함수들의 리스트입니다.\n",
    "  - 체크포인트 저장, 조기 종료 등을 위해 사용합니다.\n",
    "\n",
    "- **logger** (기본값: `True`)\n",
    "  - 학습 메트릭과 로그를 기록할 로거를 설정합니다.\n",
    "  - 기본값 `True`는 CSVLogger를 사용합니다.\n",
    "\n",
    "- **enable_checkpointing** (기본값: `True`)\n",
    "  - 자동 체크포인트 저장 기능을 활성화합니다.\n",
    "\n",
    "- **enable_progress_bar** (기본값: `True`)\n",
    "  - 학습 진행 상황을 시각적으로 보여주는 진행률 표시줄을 활성화합니다.\n",
    "\n",
    "- **enable_model_summary** (기본값: `True`)\n",
    "  - 학습 시작 시 모델 구조와 파라미터 정보를 출력합니다.\n",
    "\n",
    "- **log_every_n_steps** (기본값: `50`)\n",
    "  - 지정된 스텝마다 로그를 기록합니다.\n",
    "  - 너무 자주 로깅하면 성능에 영향을 줄 수 있습니다.\n",
    "\n",
    "- **val_check_interval** (기본값: `1.0`)\n",
    "  - 검증을 실행할 간격을 설정합니다.\n",
    "  - `1.0`: 매 에포크마다 검증\n",
    "  - `0.5`: 에포크의 절반마다 검증\n",
    "  - `100`: 100 스텝마다 검증\n",
    "\n",
    "- **check_val_every_n_epoch** (기본값: `1`)\n",
    "  - N 에포크마다 검증을 실행합니다.\n",
    "\n",
    "- **deterministic** (기본값: `False`)\n",
    "  - 재현 가능한 결과를 위해 모든 연산을 결정적으로 실행합니다.\n",
    "  - 성능이 약간 저하될 수 있지만, 실험 재현성을 보장합니다.\n",
    "\n",
    "### 사용 예시\n",
    "\n",
    "#### 최소 설정 (필수만)\n",
    "\n",
    "```python\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,  # 유일한 필수 설정\n",
    ")\n",
    "```\n",
    "\n",
    "#### 권장 설정\n",
    "\n",
    "```python\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    precision=\"16-mixed\",  # 메모리 절약\n",
    ")\n",
    "```\n",
    "\n",
    "#### 완전한 설정 (모든 옵션 명시)\n",
    "\n",
    "```\n",
    "python\n",
    "trainer = pl.Trainer(\n",
    "    # 필수 설정\n",
    "    max_epochs=args.max_epochs,\n",
    "\n",
    "    # 권장 설정\n",
    "    accelerator=args.accelerator,\n",
    "    devices=args.devices,\n",
    "    precision=args.precision,\n",
    "\n",
    "    # 선택 사항\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    "    log_every_n_steps=50,\n",
    "    val_check_interval=1.0,\n",
    "    check_val_every_n_epoch=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "```\n",
    "\n",
    "### 매개변수 기본값 정리\n",
    "\n",
    "| 파라미터                      | 기본값         | 중요도   | 설명                         |\n",
    "|---------------------------|-------------|-------|----------------------------|\n",
    "| `max_epochs`              | `None`      | 🔴 필수 | 무한 학습 방지를 위해 필수 설정         |\n",
    "| `accelerator`             | `\"auto\"`    | 🟡 권장 | 하드웨어 자동 감지                 |\n",
    "| `devices`                 | `\"auto\"`    | 🟡 권장 | 사용 가능한 모든 디바이스             |\n",
    "| `precision`               | `\"32-true\"` | 🟡 권장 | 메모리 절약을 위해 `\"16-mixed\"` 권장 |\n",
    "| `callbacks`               | `None`      | 🟢 선택 | 필요에 따라 추가                  |\n",
    "| `logger`                  | `True`      | 🟢 선택 | 기본 CSVLogger 사용            |\n",
    "| `enable_checkpointing`    | `True`      | 🟢 선택 | 체크포인트 자동 저장                |\n",
    "| `enable_progress_bar`     | `True`      | 🟢 선택 | 진행률 표시                     |\n",
    "| `enable_model_summary`    | `True`      | 🟢 선택 | 모델 요약 출력                   |\n",
    "| `log_every_n_steps`       | `50`        | 🟢 선택 | 로깅 주기                      |\n",
    "| `val_check_interval`      | `1.0`       | 🟢 선택 | 검증 간격                      |\n",
    "| `check_val_every_n_epoch` | `1`         | 🟢 선택 | 검증 에포크 주기                  |\n",
    "| `deterministic`           | `False`     | 🟢 선택 | 재현성 vs 성능 트레이드오프           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db1bce7edb0fc64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:15.677255Z",
     "start_time": "2025-07-06T10:19:15.671425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 432\n"
     ]
    }
   ],
   "source": [
    "from src.util.helper import fix_random_seed\n",
    "\n",
    "\n",
    "fix_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d25a7b70cf383cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:15.688484Z",
     "start_time": "2025-07-06T10:19:15.686434Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform 준비\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84fe963083de2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:16.168217Z",
     "start_time": "2025-07-06T10:19:15.695788Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataModule 준비\n",
    "from src.data.datamodules import DocumentImageDataModule\n",
    "\n",
    "\n",
    "data_module = DocumentImageDataModule(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_transform=train_transform,\n",
    "    test_transform=test_transform,\n",
    "    val_rate=VAL_RATE,\n",
    "    random_seed=SEED,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac42d0532fa763d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:16.618090Z",
     "start_time": "2025-07-06T10:19:16.178802Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from src.data.datasets import DocumentImageSet\n",
    "\n",
    "\n",
    "# Model 준비\n",
    "criterion = CrossEntropyLoss()\n",
    "resnet34_classifier = DocumentImageClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_classes=DocumentImageSet.calculate_metadata_classes(),\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    criterion=criterion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24e5de4b5050da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:16.632964Z",
     "start_time": "2025-07-06T10:19:16.627432Z"
    }
   },
   "outputs": [],
   "source": [
    "# 콜백 준비\n",
    "from src.training.callbacks import get_callbacks\n",
    "\n",
    "\n",
    "callbacks = get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95afd456e4701867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:19:16.672231Z",
     "start_time": "2025-07-06T10:19:16.642231Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# trainer 준비\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from src import config\n",
    "\n",
    "\n",
    "logger = CSVLogger(\n",
    "    save_dir=config.LOG_ROOT_DIR,\n",
    "    name=f\"train-log-of-{MODEL_NAME}\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=EPOCHS // 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e84969cfec31b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:21:21.241683Z",
     "start_time": "2025-07-06T10:19:16.682868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:19:16] INFO [DocumentImageDataModule.prepare_data] Done preparing data.\n",
      "[2025-07-06 19:19:20] INFO [DocumentImageDataModule.setup] Done setup\n",
      "/Users/joyuiyeong/.pyenv/versions/deeplearning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory /Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ResNet             | 21.3 M | train\n",
      "1 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "2 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "3 | train_f1       | MulticlassF1Score  | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "5 | val_f1         | MulticlassF1Score  | 0      | train\n",
      "6 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "7 | test_f1        | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.174    Total estimated model params size (MB)\n",
      "173       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd12ec4fd474f7f9d25a0a44c394922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e188c9c684a46ea80426fa53957ef6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89b8c17ef1f48e6a02744e1640cf6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.587\n",
      "Epoch 0, global step 20: 'val_loss' reached 1.58677 (best 1.58677), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=00-val_loss=1.59.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f46f33de2b434398adab0adea385b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.064 >= min_delta = 0.0. New best score: 0.523\n",
      "Epoch 1, global step 40: 'val_loss' reached 0.52262 (best 0.52262), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=01-val_loss=0.52.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4817713db64a54acbfbd5abf7b7b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.222 >= min_delta = 0.0. New best score: 0.301\n",
      "Epoch 2, global step 60: 'val_loss' reached 0.30108 (best 0.30108), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=02-val_loss=0.30-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fdcd76355a4642b2ff0842533ac4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.31631 (best 0.30108), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=03-val_loss=0.32.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dfee48e5f7452a93381a366c836b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.301\n",
      "Epoch 4, global step 100: 'val_loss' reached 0.30101 (best 0.30101), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=04-val_loss=0.30-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d1c8e57f264f7e8b988df65db789c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.040 >= min_delta = 0.0. New best score: 0.261\n",
      "Epoch 5, global step 120: 'val_loss' reached 0.26076 (best 0.26076), saving model to '/Users/joyuiyeong/projects/upstageailab-cv-classification-cv_3/data/raw/checkpoints/epoch=05-val_loss=0.26-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4d01799d994e04967ae2aa9f8c5fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f1e81aef1047208c4262a2c90c747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4971925feb9465896c553b890a42278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7142de6b831348a3864bbf4744435490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "trainer.fit(model=resnet34_classifier, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
