import os
import zipfile # ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Python Imaging Library)
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image # zip íŒŒì¼ ì—´ê¸°ìš©
import math # í–‰/ì—´ ìˆ˜ ê³„ì‚°ìš©
import numpy as np
from sklearn.model_selection import train_test_split

# í•œê¸€ í°íŠ¸ ì„¤ì • (ê·¸ë˜í”„ì— ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì • - ìœˆë„ìš° ê¸°ë³¸ Malgun Gothic)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤(-) ê¹¨ì§ ë°©ì§€

# train.csvì—ëŠ” ì´ë¯¸ì§€ IDì™€ ë¼ë²¨(label) ì •ë³´ê°€ ë“¤ì–´ìˆë‹¤.
train_df = pd.read_csv(r"C:\Users\ì¬í˜•ë \Desktop\ì½”ë”©ì¹œêµ¬ë“¤\ì»´í“¨í„°ë¹„ì „ í”„ë¡œì íŠ¸\datasets_folder\data\train.csv")
meta_df = pd.read_csv(r"C:\Users\ì¬í˜•ë \Desktop\ì½”ë”©ì¹œêµ¬ë“¤\ì»´í“¨í„°ë¹„ì „ í”„ë¡œì íŠ¸\datasets_folder\data\meta.csv")

# ê²½ë¡œ ì„¤ì •
DATA_DIR = r"C:\Users\ì¬í˜•ë \Desktop\ì½”ë”©ì¹œêµ¬ë“¤\ì»´í“¨í„°ë¹„ì „ í”„ë¡œì íŠ¸\datasets_folder\data"
TRAIN_CSV_PATH = os.path.join(DATA_DIR, "train.csv")
META_CSV_PATH = os.path.join(DATA_DIR, "meta.csv")
TRAIN_ZIP_PATH = os.path.join(DATA_DIR, "train.zip")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ê¸°ë³¸ ì •ë³´ EDA
def eda_basic_info(train_df, meta_df):
    print("ğŸ“¦ [train.csv ì •ë³´]")
    print(train_df.info())
    print("\nğŸ“¦ [meta.csv ì •ë³´]")
    print(meta_df.info())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”
def eda_label_distribution(train_df, meta_df):
    # [2] train.csvì—ëŠ” 1570ê°œì˜ ìƒ˜í”Œê³¼ 17ê°œì˜ í´ë˜ìŠ¤(target)ê°€ ìˆìŒ
    # ë¼ë²¨(target)ì˜ ë¶„í¬ í™•ì¸ (í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ìˆëŠ”ì§€ ë³´ê¸° ìœ„í•¨)
    label_counts = train_df['target'].value_counts().sort_index()

    # [3] ë³´ê¸° ì¢‹ê²Œ DataFrame í˜•íƒœë¡œ ë³€í™˜ (ì‹œê°í™”, ë¶„ì„ì— í¸ë¦¬)
    label_df = pd.DataFrame({
        'target': label_counts.index,
        'count': label_counts.values
    })

    # [4] meta.csvì˜ class_nameê³¼ targetì„ mergeí•´ì„œ ë³´ê¸° ì‰½ê²Œ ì´ë¦„ ë¶™ì´ê¸°
    label_df = label_df.merge(meta_df, on='target', how='left')

    # [5] ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
    plt.figure(figsize=(14, 6))

    # [6] Seaborn ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ì‹œê°í™” (x: í´ë˜ìŠ¤ëª…, y: ê°œìˆ˜)
    sns.barplot(x='class_name', y='count', data=label_df)

    # [7] ê·¸ë˜í”„ ì œëª©, ë¼ë²¨ ì„¤ì •
    plt.title("í´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬ : train.csv ê¸°ì¤€")
    plt.xlabel("í´ë˜ìŠ¤ ì´ë¦„")
    plt.ylabel("ìƒ˜í”Œ ìˆ˜")
    plt.xticks(rotation=90, fontsize=10)  # ê¸€ìê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ íšŒì „
    plt.grid(axis='y')
    plt.tight_layout()

    # [8] ê·¸ë˜í”„ ì¶œë ¥
    plt.show()

    
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ì‹œê°í™”
def eda_visualize_images(train_df, zip_path, samples_per_class=2):
    """
    ğŸ“Œ ì„¤ëª…:
    ì´ í•¨ìˆ˜ëŠ” train.csvì—ì„œ ê° ë¼ë²¨(class)ë§ˆë‹¤ ëœë¤ìœ¼ë¡œ ì´ë¯¸ì§€ ëª‡ ê°œì”© ì¶”ì¶œí•´ì„œ
    zip ì•ˆì—ì„œ ì§ì ‘ ì—´ê³ , í™”ë©´ì— ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜ì•¼.
    
    - train_df: train.csvë¥¼ pandasë¡œ ì½ì–´ì˜¨ ë°ì´í„°í”„ë ˆì„
    - zip_path: train ì´ë¯¸ì§€ê°€ ë‹´ê¸´ ì••ì¶•íŒŒì¼ ê²½ë¡œ (ì˜ˆ: train.zip)
    - samples_per_class: í´ë˜ìŠ¤ë§ˆë‹¤ ì¶œë ¥í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ê°’ì€ 2ê°œ)
    """
     # [1] í´ë˜ìŠ¤(target) ë³„ë¡œ groupbyí•´ì„œ, í´ë˜ìŠ¤ë§ˆë‹¤ ë¬´ì‘ìœ„ë¡œ Nê°œì”© ìƒ˜í”Œë§
    # group_keys=Falseë¥¼ ì„¤ì •í•´ì„œ ê²½ê³  ë°©ì§€ (pandas ìµœì‹ ë²„ì „ìš©)
    sample_df = train_df.groupby('target', group_keys=False).apply(
        lambda x: x.sample(n=samples_per_class, random_state=42)
    ).reset_index(drop=True)

    # [2] train.zip íŒŒì¼ì„ ì—°ë‹¤ (íŒŒì¼ì„ ì••ì¶• í’€ì§€ ì•Šê³  ë‚´ë¶€ì—ì„œ ë°”ë¡œ ì½ì„ ìˆ˜ ìˆê²Œ í•¨)
    with zipfile.ZipFile(zip_path, 'r') as archive:

        num_images = len(sample_df)  # ì „ì²´ ì‹œê°í™”í•  ì´ë¯¸ì§€ ìˆ˜

        # [3] ì¶œë ¥í•  subplotì˜ í–‰/ì—´ ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°
        cols = 9                                   # í•œ ì¤„ì— 9ê°œì˜ ì´ë¯¸ì§€ ì¶œë ¥
        rows = math.ceil(num_images / cols)        # í•„ìš”í•œ ì¤„ ìˆ˜ ê³„ì‚°

        # [4] í–‰ë ¬ í˜•íƒœë¡œ subplot ê·¸ë¦¬ê¸° (ê·¸ë˜í”„ ê·¸ë¦´ í‹€ ë§Œë“œëŠ” ë‹¨ê³„)
        fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 2, rows * 2))
        axes = axes.flatten()  # 2ì°¨ì› â†’ 1ì°¨ì›ìœ¼ë¡œ í¼ì³ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë‹¤ë£¨ê¸° ì‰½ê²Œ ë³€í™˜

        # [5] ì´ë¯¸ì§€ í•˜ë‚˜ì”© ìˆœíšŒí•˜ë©´ì„œ zipì—ì„œ ì—´ê³  ì¶œë ¥
        for i, (idx, row) in enumerate(sample_df.iterrows()):
            # [5-1] ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆ: '000001')
            img_name = row['ID']
            
            # [5-2] í™•ì¥ì ëˆ„ë½ ë°©ì§€ â†’ .jpgê°€ ì—†ìœ¼ë©´ ë¶™ì´ê¸°
            if not img_name.endswith(".jpg"):
                img_name += ".jpg"
            
            # [5-3] zip íŒŒì¼ ì•ˆì—ì„œì˜ ê²½ë¡œ êµ¬ì„± (ì˜ˆ: train/000001.jpg)
            img_path = f"train/{img_name}"

            # [5-4] ì´ë¯¸ì§€ zip ì•ˆì—ì„œ ì—´ê¸° â†’ ì˜¤ë¥˜ ìƒê¸°ë©´ KeyError ì²˜ë¦¬
            try:
                with archive.open(img_path) as file:
                    img = Image.open(file).convert("RGB")     # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° & RGBë¡œ ë³€í™˜
                    axes[i].imshow(img)                       # subplotì— ì´ë¯¸ì§€ í‘œì‹œ
                    axes[i].axis('off')                       # ì¶• ì œê±° (ê¹”ë”í•˜ê²Œ ë³´ì´ê²Œ)
                    axes[i].set_title(f"Label: {row['target']}", fontsize=8)  # ë¼ë²¨ í‘œì‹œ

            except KeyError:
                # ë§Œì•½ ì´ë¯¸ì§€ê°€ zip ì•ˆì— ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ â†’ ëŒ€ì‹  ë¹ˆ ì¹¸ ì²˜ë¦¬
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŒ: {img_path}")
                axes[i].axis('off')
                axes[i].set_title("ì´ë¯¸ì§€ ì—†ìŒ", fontsize=8)

        # [6] ì¶œë ¥í•œ ì´ë¯¸ì§€ ìˆ˜ë³´ë‹¤ subplotì´ ë” ë§ì„ ê²½ìš° â†’ ë‚¨ì€ ì¹¸ì€ ë¹„ìš°ê¸°
        for j in range(i + 1, len(axes)):
            axes[j].axis('off')

        # [7] ì „ì²´ ë ˆì´ì•„ì›ƒ ì •ë¦¬ + í™”ë©´ì— ì¶œë ¥
        plt.tight_layout()
        plt.show()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì´ë¯¸ì§€ í•´ìƒë„ ë¶„ì„
def eda_image_resolution_stats(train_df, zip_path, sample_size=300):
    """
    ğŸ“Œ ì„¤ëª…:
    ì´ í•¨ìˆ˜ëŠ” zip ì•ˆì— ìˆëŠ” ì´ë¯¸ì§€ë“¤ì˜ í•´ìƒë„(ë„ˆë¹„, ë†’ì´)ë¥¼ í™•ì¸í•´ì„œ
    í‰ê· , ìµœì†Œ, ìµœëŒ€ í¬ê¸°ì™€ ë¶„í¬ë¥¼ ì‹œê°í™”í•´ì£¼ëŠ” í•¨ìˆ˜ì•¼.

    - train_df: train.csvë¥¼ ë¶ˆëŸ¬ì˜¨ pandas DataFrame
    - zip_path: train.zip ì••ì¶• íŒŒì¼ ê²½ë¡œ
    - sample_size: ìƒ˜í”Œë§í•  ì´ë¯¸ì§€ ìˆ˜ (ì „ì²´ ë‹¤ í™•ì¸í•˜ë©´ ëŠë¦´ ìˆ˜ ìˆì–´ì„œ ì¼ë¶€ë§Œ ë´ë„ ì¶©ë¶„í•¨)
    """

    widths = []   # ì´ë¯¸ì§€ ë„ˆë¹„ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    heights = []  # ì´ë¯¸ì§€ ë†’ì´ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸

    # zip íŒŒì¼ ì—´ê¸°
    with zipfile.ZipFile(zip_path, 'r') as archive:
        # ë¬´ì‘ìœ„ë¡œ sample_sizeë§Œí¼ ID ì¶”ì¶œ
        for img_id in train_df['ID'].sample(n=sample_size, random_state=42):
            
            # í™•ì¥ì ì¤‘ë³µ ë°©ì§€ ì²˜ë¦¬
            if not img_id.endswith(".jpg"):
                img_name = img_id + ".jpg"
            else:
                img_name = img_id

            # zip ì•ˆì˜ ê²½ë¡œëŠ” train í´ë” ì•ˆì— ìˆìŒ
            img_path = f"train/{img_name}"

            try:
                # ì´ë¯¸ì§€ íŒŒì¼ ì—´ê¸°
                with archive.open(img_path) as file:
                    img = Image.open(file)

                    # ë„ˆë¹„ì™€ ë†’ì´ ì €ì¥
                    widths.append(img.width)
                    heights.append(img.height)

            except KeyError:
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ ëˆ„ë½: {img_path} (zip ì•ˆì— ì—†ìŒ)")
                continue  # ëˆ„ë½ëœ ê²½ìš° ê·¸ëƒ¥ ë„˜ì–´ê°

    # ğŸ“ í†µê³„ ì¶œë ¥
    print("ğŸ“ ì´ë¯¸ì§€ í•´ìƒë„ í†µê³„:")
    print(f" - í‰ê·  í•´ìƒë„: {int(np.mean(widths))} x {int(np.mean(heights))}")
    print(f" - ìµœì†Œ í•´ìƒë„: {min(widths)} x {min(heights)}")
    print(f" - ìµœëŒ€ í•´ìƒë„: {max(widths)} x {max(heights)}")

    # ğŸ“Š ë¶„í¬ ì‹œê°í™” (íˆìŠ¤í† ê·¸ë¨)
    # ğŸ“Š ë„ˆë¹„/ë†’ì´ë¥¼ ë”°ë¡œ subplotìœ¼ë¡œ ê·¸ë ¤ì„œ êµ¬ë¶„!
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # ë„ˆë¹„ íˆìŠ¤í† ê·¸ë¨
    sns.histplot(widths, kde=True, color="skyblue", ax=ax1)
    ax1.set_title("ì´ë¯¸ì§€ ë„ˆë¹„(width) ë¶„í¬")
    ax1.set_xlabel("í”½ì…€")
    ax1.set_ylabel("Count")
    ax1.grid()

    # ë†’ì´ íˆìŠ¤í† ê·¸ë¨
    sns.histplot(heights, kde=True, color="orange", ax=ax2)
    ax2.set_title("ì´ë¯¸ì§€ ë†’ì´(height) ë¶„í¬")
    ax2.set_xlabel("í”½ì…€")
    ax2.set_ylabel("Count")
    ax2.grid()

    plt.tight_layout()
    plt.show()

def compute_classwise_brightness(train_df, TRAIN_ZIP_PATH, sample_per_class=10):
    """
    ê° í´ë˜ìŠ¤(class_name)ë³„ë¡œ ì´ë¯¸ì§€ ëª‡ ì¥ì”© ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§í•´ì„œ
    í‰ê·  ë°ê¸°ë¥¼ ê³„ì‚°í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    train_df = train_df.merge(meta_df, on="target", how="left")

    brightness_data = []

    # zip ì••ì¶•ëœ ì´ë¯¸ì§€ íŒŒì¼ ì—´ê¸°
    with zipfile.ZipFile(TRAIN_ZIP_PATH, 'r') as archive:
        # í´ë˜ìŠ¤ë³„ ê·¸ë£¹í™”
        grouped = train_df.groupby('class_name')

        for class_name, group in grouped:
            # ê° í´ë˜ìŠ¤ì—ì„œ sample_per_class ê°œìˆ˜ë§Œí¼ ë¬´ì‘ìœ„ ìƒ˜í”Œë§
            sampled = group.sample(n=min(sample_per_class, len(group)), random_state=42)

            for _, row in sampled.iterrows():
                img_id = row['ID']
                if not img_id.endswith(".jpg"):
                    img_id += ".jpg"

                img_path = f"train/{img_id}"

                try:
                    # ì´ë¯¸ì§€ ì—´ê³  í‘ë°±ìœ¼ë¡œ ë³€í™˜ â†’ ë°ê¸° ê³„ì‚°
                    with archive.open(img_path) as file:
                        img = Image.open(file).convert("L")  # "L"ì€ í‘ë°± ëª¨ë“œ
                        brightness = np.mean(np.array(img))  # í”½ì…€ í‰ê·  (0~255)
                        brightness_data.append({
                            'class_name': class_name,
                            'brightness': brightness
                        })
                except:
                    continue  # ì´ë¯¸ì§€ ì—†ìœ¼ë©´ ë„˜ì–´ê°

    return pd.DataFrame(brightness_data)


#eda_basic_info(train_df, meta_df)
#eda_label_distribution(train_df, meta_df)
# eda_visualize_images(train_df, TRAIN_ZIP_PATH, samples_per_class=2)
# eda_image_resolution_stats(train_df, TRAIN_ZIP_PATH)

# brightness_df = compute_classwise_brightness(train_df, TRAIN_ZIP_PATH, sample_per_class=100)

# í´ë˜ìŠ¤ë³„ í‰ê·  ë°ê¸° ì‹œê°í™”
# plt.figure(figsize=(23, 8))
# sns.barplot(x='class_name', y='brightness', data=brightness_df, estimator=np.mean, palette='coolwarm')
# plt.title("í´ë˜ìŠ¤ë³„ í‰ê·  ì´ë¯¸ì§€ ë°ê¸°")
# plt.xlabel("ë¬¸ì„œ í´ë˜ìŠ¤")
# plt.ylabel("í‰ê·  ë°ê¸° (0~255)")
# plt.xticks(rotation=60, ha='right')
# plt.grid(axis='y')
# plt.tight_layout()
# plt.show()

#-----------------------------------------
# ---------- Validation Set ìƒì„±----------
#-----------------------------------------

# âœ… 1. ë°ì´í„° ë¡œë“œ (EDAì™€ ë™ì¼í•œ ê²½ë¡œ ì‚¬ìš©)
train_df = pd.read_csv(r"C:\Users\ì¬í˜•ë \Desktop\ì½”ë”©ì¹œêµ¬ë“¤\ì»´í“¨í„°ë¹„ì „ í”„ë¡œì íŠ¸\datasets_folder\data\train.csv")
meta_df  = pd.read_csv(r"C:\Users\ì¬í˜•ë \Desktop\ì½”ë”©ì¹œêµ¬ë“¤\ì»´í“¨í„°ë¹„ì „ í”„ë¡œì íŠ¸\datasets_folder\data\meta.csv")

# âœ… 2. í´ë˜ìŠ¤ ì´ë¦„(class_name) ë¶™ì´ê¸° ìœ„í•´ merge
# train.csvì—ëŠ” ìˆ«ìí˜• targetì´ ìˆê³ , meta.csvì—ëŠ” targetì— í•´ë‹¹í•˜ëŠ” class_nameì´ ìˆìŒ
merged_df = train_df.merge(meta_df, on='target', how='left')

# âœ… 3. Stratified ë°©ì‹ìœ¼ë¡œ Validation Set ìƒì„±
# - stratify íŒŒë¼ë¯¸í„°ë¡œ í´ë˜ìŠ¤(target) ë¶„í¬ ìœ ì§€
# - random_state: ì‹¤í—˜ ì¬í˜„ì„± ê³ ì •
train_split, valid_split = train_test_split(
    merged_df,
    test_size=0.2,              # ì „ì²´ ë°ì´í„° ì¤‘ 20%ë¥¼ validation setìœ¼ë¡œ ì‚¬ìš©
    stratify=merged_df['target'],  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
    random_state=42             # ëœë¤ì„± í†µì œ
)

# âœ… 4. ê²°ê³¼ í™•ì¸ (í´ë˜ìŠ¤ë³„ ë¹„ìœ¨ ë¹„êµ)
print("âœ”ï¸ [Train í´ë˜ìŠ¤ ë¶„í¬]")
print(train_split['target'].value_counts(normalize=True).sort_index())

print("\nâœ”ï¸ [Validation í´ë˜ìŠ¤ ë¶„í¬]")
print(valid_split['target'].value_counts(normalize=True).sort_index())

# âœ… 5. ì„ íƒì ìœ¼ë¡œ ì €ì¥ ê°€ëŠ¥ (í•™ìŠµì—ì„œ ì‚¬ìš©í•  ê²½ìš°)
train_split.to_csv("train_split.csv", index=False)
valid_split.to_csv("valid_split.csv", index=False)